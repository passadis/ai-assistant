{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bcb953c-1e64-4b32-8b62-e28a4760b51a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**Copy Books Dataset to Azure AI Search**\n",
    "\n",
    "- Create the Index\n",
    "- Validate Data\n",
    "- Copy Data to index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb23d98f-6200-4e00-90af-2f9bf294d334",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import SearchIndex, SimpleField, SearchFieldDataType, SearchField, ComplexField\n",
    "\n",
    "# Define your Azure Cognitive Search service and API key\n",
    "service_name = 'xxxxxxxxx'\n",
    "admin_key = 'xxxxxxxxxx'\n",
    "index_name = 'books-index'\n",
    "\n",
    "# Create a client\n",
    "endpoint = f'https://{service_name}.search.windows.net'\n",
    "admin_client = SearchIndexClient(endpoint=endpoint, credential=AzureKeyCredential(admin_key))\n",
    "\n",
    "# Define the fields of the index\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, retrievable=True, stored=True),\n",
    "    SearchField(name=\"Title\", type=SearchFieldDataType.String, searchable=True, filterable=True, retrievable=True, stored=True, analyzer_name=\"standard.lucene\"),\n",
    "    SearchField(name=\"Description\", type=SearchFieldDataType.String, searchable=True, filterable=False, retrievable=True, stored=True, analyzer_name=\"standard.lucene\"),\n",
    "    SearchField(name=\"Author\", type=SearchFieldDataType.String, searchable=True, filterable=True, retrievable=True, stored=True, sortable=True, facetable=True, analyzer_name=\"standard.lucene\"),\n",
    "    SearchField(name=\"Genres\", type=SearchFieldDataType.Collection(SearchFieldDataType.String), searchable=True, filterable=True, retrievable=True, stored=True, facetable=True, analyzer_name=\"standard.lucene\"),\n",
    "    SimpleField(name=\"Rating\", type=SearchFieldDataType.Double, filterable=True, retrievable=True, stored=True, sortable=True, facetable=True)\n",
    "]\n",
    "\n",
    "# Define the index\n",
    "index = SearchIndex(name=index_name, fields=fields)\n",
    "\n",
    "# Create the index\n",
    "admin_client.create_index(index)\n",
    "print(f'Index \"{index_name}\" created successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1350c8-4100-4ec3-a488-af2f42604c8c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import json\n",
    "\n",
    "# Define your Azure Cognitive Search credentials and endpoint\n",
    "service_endpoint = \"https://azaivztqx.search.windows.net\"\n",
    "index_name = \"books-index\"\n",
    "admin_key = \"UvNc9RS47BkkZi0Hz7XPdSkpvi9QXDuqbg6rrejGw5AzSeBxWhxe\"\n",
    "\n",
    "# Create a SearchClient\n",
    "client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=AzureKeyCredential(admin_key))\n",
    "\n",
    "# Load the JSON data\n",
    "output_file = \"/lakehouse/default/Files/bookersdata.json\"\n",
    "with open(output_file, 'r') as file:\n",
    "    documents = json.load(file)  # Load the JSON array directly\n",
    "\n",
    "# Initialize lists for valid and invalid documents\n",
    "valid_documents = []\n",
    "invalid_documents = []  # <-- Declare this list here\n",
    "\n",
    "# Ensure all required fields, including the description, are present\n",
    "for doc in documents:\n",
    "    if 'Description' not in doc:\n",
    "        doc['Description'] = ''  # Fill missing descriptions with an empty string\n",
    "\n",
    "# Validate each document\n",
    "for doc in documents:\n",
    "    valid = True\n",
    "    \n",
    "    # Validate and convert Rating to float\n",
    "    if 'Rating' in doc:\n",
    "        try:\n",
    "            doc['Rating'] = float(doc['Rating'])\n",
    "        except ValueError:\n",
    "            print(f\"Invalid value for Rating in document ID {doc.get('id', 'unknown')}: {doc['Rating']}\")\n",
    "            invalid_documents.append(doc)\n",
    "            valid = False\n",
    "    \n",
    "    # Validate Genres is a list of strings\n",
    "    if 'Genres' in doc:\n",
    "        if isinstance(doc['Genres'], str):\n",
    "            try:\n",
    "                doc['Genres'] = json.loads(doc['Genres'])\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Invalid JSON format for Genres in document ID {doc.get('id', 'unknown')}: {doc['Genres']}\")\n",
    "                invalid_documents.append(doc)\n",
    "                valid = False\n",
    "        elif isinstance(doc['Genres'], list):\n",
    "            if not all(isinstance(genre, str) for genre in doc['Genres']):\n",
    "                print(f\"Unexpected format for Genres in document ID {doc.get('id', 'unknown')}: {doc['Genres']}\")\n",
    "                invalid_documents.append(doc)\n",
    "                valid = False\n",
    "        else:\n",
    "            print(f\"Unexpected format for Genres in document ID {doc.get('id', 'unknown')}: {doc['Genres']}\")\n",
    "            invalid_documents.append(doc)\n",
    "            valid = False\n",
    "    \n",
    "    if valid:\n",
    "        valid_documents.append(doc)\n",
    "\n",
    "# Log the number of valid and invalid documents\n",
    "print(f\"Valid documents: {len(valid_documents)}\")\n",
    "print(f\"Invalid documents: {len(invalid_documents)}\")\n",
    "\n",
    "# Upload valid documents to the Azure Search index\n",
    "if valid_documents:\n",
    "    result = client.upload_documents(documents=valid_documents)\n",
    "    print(f\"Uploaded {len(valid_documents)} documents to the Azure Search index. Results: {result}\")\n",
    "else:\n",
    "    print(\"No valid documents to upload.\")\n"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {
    "environmentId": "d5a85687-f4c8-4dae-86ec-ba90dc32a717",
    "workspaceId": "9750728a-936e-41b9-a6cd-1247d645f4c5"
   },
   "lakehouse": {
    "default_lakehouse": "83b65b13-7f82-4177-838c-f19a8134860b",
    "default_lakehouse_name": "Datasets",
    "default_lakehouse_workspace_id": "9750728a-936e-41b9-a6cd-1247d645f4c5"
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
