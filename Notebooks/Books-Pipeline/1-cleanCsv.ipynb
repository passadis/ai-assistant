{"cells":[{"cell_type":"code","source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code!\n","# %pip install pandas\n","# abfss://Data@onelake.dfs.fabric.microsoft.com/Datasets.Lakehouse/Files/booksdata.csv\n","# Files/booksdata.csv"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5f68967e-253c-4d35-be30-7a0b16a7e0fb"},{"cell_type":"markdown","source":["- **CLEAN CSV**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2b2668cd-20f5-48d7-88a3-47303d54203f"},{"cell_type":"code","source":["from pyspark.sql.functions import udf, col\n","from pyspark.sql.types import BooleanType\n","import re\n","\n","# Read the CSV file into a Spark DataFrame\n","df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"abfss://Data@onelake.dfs.fabric.microsoft.com/Datasets.Lakehouse/Files/books.csv\")\n","display(df)\n","\n","# Define the UDF to check for non-ASCII characters\n","def has_non_ascii(value):\n","    if value is None:\n","        return False\n","    return bool(re.search(r'[^\\x00-\\x7F]', value))\n","\n","# Register the UDF\n","has_non_ascii_udf = udf(has_non_ascii, BooleanType())\n","\n","# Apply the UDF to each column that needs to be checked\n","df_clean = df.filter(~has_non_ascii_udf(col(\"Book\")) & \n","                     ~has_non_ascii_udf(col(\"Author\")) & \n","                     ~has_non_ascii_udf(col(\"Genres\")))\n","\n","# Display the cleaned DataFrame\n","display(df_clean)\n","\n","# Coalesce the DataFrame to a single partition\n","df_clean_coalesced = df_clean.coalesce(1)\n","\n","# Save the coalesced DataFrame to a new CSV file in Azure Data Lake Storage\n","cleaned_file_path = \"abfss://Data@onelake.dfs.fabric.microsoft.com/Datasets.Lakehouse/Files/booksclean\"\n","df_clean_coalesced.write.format(\"csv\").option(\"header\", \"true\").mode(\"overwrite\").save(cleaned_file_path)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"549e66cd-6ac5-4ebf-8187-e6e768211dbc"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"83b65b13-7f82-4177-838c-f19a8134860b","known_lakehouses":[{"id":"83b65b13-7f82-4177-838c-f19a8134860b"}],"default_lakehouse_name":"Datasets","default_lakehouse_workspace_id":"9750728a-936e-41b9-a6cd-1247d645f4c5"}}},"nbformat":4,"nbformat_minor":5}